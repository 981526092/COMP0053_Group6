{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import os\n",
    "from typing import Union\n",
    "\n",
    "import numpy as np\n",
    "import scipy.io\n",
    "from scipy.stats import mode\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score, precision_score, recall_score, f1_score, \\\n",
    "    confusion_matrix\n",
    "from sklearn.svm import SVC"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "train_path = \"CoordinateData\\\\train\"\n",
    "validation_path = \"CoordinateData\\\\validation\""
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "def segment_data(data: np.ndarray, window_size: int = 180, overlap_ratio: float = 0.75, by_type: bool = True, min_frame: int = 12) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Segment the input data into smaller windows based on the given parameters.\n",
    "\n",
    "    Args:\n",
    "        data (np.ndarray): Input data with shape (num_samples, num_features).\n",
    "        window_size (int, optional): The length of each window. Defaults to 180.\n",
    "        overlap_ratio (float, optional): The ratio of overlap between consecutive windows. Defaults to 0.75.\n",
    "        by_type (bool, optional): Whether to segment the data by type (assuming the 71st feature is the type). Defaults to True.\n",
    "        min_frame (int, optional): The minimum number of frames required to create a new instance. Defaults to 12.\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: The segmented data with shape (num_windows, window_size, num_features).\n",
    "    \"\"\"\n",
    "\n",
    "    # Check the input constraints\n",
    "    assert data.shape[0] > 0\n",
    "    assert window_size > 0\n",
    "    assert 0 <= overlap_ratio < 1\n",
    "    assert 0 <= min_frame < window_size\n",
    "\n",
    "    dim = data.shape[1]\n",
    "    instances = []\n",
    "\n",
    "    if not by_type:\n",
    "        instances.append(data)\n",
    "    else:\n",
    "        assert data.shape[1] >= 71\n",
    "\n",
    "        num_data = data.shape[0]\n",
    "        left, right = 0, 1\n",
    "        pre_type = -1\n",
    "        cur_type = data[left, 70]\n",
    "\n",
    "        # Segment the data by exercise type\n",
    "        while right < num_data:\n",
    "            if data[right, 70] == cur_type:\n",
    "                right += 1\n",
    "                continue\n",
    "\n",
    "            if right - left <= min_frame:\n",
    "                left = right\n",
    "                cur_type = data[left, 70]\n",
    "                right += 1\n",
    "                continue\n",
    "\n",
    "            new_instance = np.take(data, range(left, right), axis=0)\n",
    "            if pre_type == new_instance[0, 70]:\n",
    "                instances[-1] = np.vstack([instances[-1], new_instance])\n",
    "            else:\n",
    "                instances.append(new_instance)\n",
    "\n",
    "            left = right\n",
    "            pre_type = cur_type\n",
    "            cur_type = data[left, 70]\n",
    "            right += 1\n",
    "\n",
    "        # Handle the remaining data\n",
    "        new_instance = np.take(data, range(left, right), axis=0)\n",
    "        last = instances[-1]\n",
    "        if last[0, 70] == new_instance[0, 70]:\n",
    "            instances[-1] = np.vstack([last, new_instance])\n",
    "        else:\n",
    "            instances.append(new_instance)\n",
    "\n",
    "    # print(len(instances))\n",
    "\n",
    "    step_size = int(window_size * (1 - overlap_ratio))\n",
    "    windows = []\n",
    "\n",
    "    # Create windows for each instance\n",
    "    for instance in instances:\n",
    "        if instance.shape[0] < window_size:\n",
    "            instance = np.vstack([instance, np.zeros((window_size - instance.shape[0], dim))])\n",
    "            windows.append(instance)\n",
    "            continue\n",
    "\n",
    "        if (instance.shape[0] - window_size) % step_size != 0:\n",
    "            pad_size = step_size - (instance.shape[0] - window_size) % step_size\n",
    "            instance = np.vstack([instance, np.zeros((pad_size, dim))])\n",
    "\n",
    "        for i in range(0, instance.shape[0] - window_size + 1, step_size):\n",
    "            windows.append(np.take(instance, range(i, i + window_size), axis=0))\n",
    "\n",
    "    return np.array(windows)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "def ensemble_predict(y_predicts: np.ndarray, scores: np.ndarray, ensemble_method: int = 0) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Perform ensemble prediction using different methods based on multiple models' predictions and their confusion matrices.\n",
    "\n",
    "    Parameters:\n",
    "    y_predicts (np.ndarray): A 3D array of shape (num_modalities, num_windows, 2) containing prediction probabilities for each modality.\n",
    "    scores (np.ndarray): A 2D array of shape (num_modalities, 4) containing metrics (accuracy, precision, recall, and F1-score) for each modality.\n",
    "    ensemble_method (int): An integer (0-7) indicating the ensemble method to be used. Default is 0 (Simple Average).\n",
    "\n",
    "    Returns:\n",
    "    np.ndarray: A 1D array of shape (num_windows,) containing the ensemble predictions for each window.\n",
    "    \"\"\"\n",
    "\n",
    "    # Check input assertions\n",
    "    assert y_predicts.shape[0] > 1\n",
    "    assert y_predicts.shape[2] == 2\n",
    "    assert y_predicts.shape[0] == scores.shape[0]\n",
    "    assert 0 <= ensemble_method < 8\n",
    "\n",
    "    num_modalities = y_predicts.shape[0]\n",
    "    num_windows = y_predicts.shape[1]\n",
    "    print(f'{num_windows} data are predicted using combined results of {num_modalities} modalities')\n",
    "\n",
    "    # Perform ensemble prediction based on the selected method\n",
    "    if ensemble_method == 0:                                            # Simple Average\n",
    "        final_predict = np.argmax(np.mean(y_predicts, axis=0), axis=1)\n",
    "    elif ensemble_method in [1, 2, 3, 4]:                               # Weighted Average (using different metrics)\n",
    "        accuracies = []\n",
    "        precisions = []\n",
    "        recalls = []\n",
    "        f1_scores = []\n",
    "\n",
    "        for m in scores:\n",
    "            accuracy, precision, recall, f1 = m.ravel()\n",
    "\n",
    "            accuracies.append(accuracy)\n",
    "            precisions.append(precision)\n",
    "            recalls.append(recall)\n",
    "            f1_scores.append(f1)\n",
    "\n",
    "        # Normalize the metrics\n",
    "        accuracies = np.array(accuracies) / np.sum(accuracies)\n",
    "        precisions = np.array(precisions) if np.sum(precisions) == 0 else np.array(precisions) / np.sum(precisions)\n",
    "        recalls = np.array(recalls) if np.sum(recalls) == 0 else np.array(recalls) / np.sum(recalls)\n",
    "        f1_scores = np.array(f1_scores) if np.sum(f1_scores) == 0 else np.array(f1_scores) / np.sum(f1_scores)\n",
    "\n",
    "        metrics = {\n",
    "                1: accuracies,\n",
    "                2: precisions,\n",
    "                3: recalls,\n",
    "                4: f1_scores\n",
    "        }\n",
    "        # Choose the appropriate metric for weighted averaging\n",
    "        weights = metrics[ensemble_method]\n",
    "\n",
    "        # Perform weighted averaging\n",
    "        y_predicts = weights[:, np.newaxis, np.newaxis] * y_predicts\n",
    "        final_predict = np.argmax(np.sum(y_predicts, axis=0), axis=1)\n",
    "    elif ensemble_method == 5:                                          # Maximum Rule\n",
    "        final_predict = np.argmax(np.max(y_predicts, axis=0), axis=1)\n",
    "    elif ensemble_method == 6:                                          # Product Rule\n",
    "        final_predict = np.argmax(np.prod(y_predicts, axis=0), axis=1)\n",
    "    else:                                                               # Voting\n",
    "        final_predict, _ = mode(np.argmax(y_predicts, axis=2), axis=0)\n",
    "        final_predict = final_predict.flatten()\n",
    "\n",
    "    return final_predict"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "def load_data(path: str, downsampling: bool, concat: bool, seg_parameters: dict = None) -> (Union[list, np.ndarray], Union[list, np.ndarray]):\n",
    "    X_list = []\n",
    "    y_list = []\n",
    "\n",
    "    selected_data_list = []\n",
    "\n",
    "    # Iterate through the files in the provided path\n",
    "    for file in os.listdir(path):\n",
    "        mat = scipy.io.loadmat(os.path.join(path, file))\n",
    "\n",
    "        # If downsampling is True, ignore data with only one unique value in column 72\n",
    "        if downsampling and np.unique(mat['data'][:, 72]).size == 1:\n",
    "            continue\n",
    "        else:\n",
    "            selected_data_list.append(mat['data'])\n",
    "\n",
    "    # Process and segment the selected data files\n",
    "    for data in selected_data_list:\n",
    "\n",
    "        # If seg_parameters are provided, segment the data using those parameters\n",
    "        processed_data = segment_data(data, **seg_parameters) if seg_parameters else segment_data(data)\n",
    "\n",
    "        # Extract feature data (columns 0 to 69) and labels (column 72)\n",
    "        X_segmented = processed_data[:, :, 0:70]\n",
    "        y_segmented = processed_data[:, :, 72]\n",
    "        y_segmented = np.apply_along_axis(lambda x: mode(x)[0], 1, y_segmented)\n",
    "\n",
    "        X_list.append(X_segmented)\n",
    "        y_list.append(y_segmented.flatten())\n",
    "\n",
    "    # If concat is True, concatenate the lists into numpy arrays\n",
    "    if concat:\n",
    "        return np.concatenate(X_list, axis=0), np.concatenate(y_list, axis=0)\n",
    "\n",
    "    return X_list, y_list"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The code below feeds coordinate information as a modality to the Random Forest for training and provides surface electromyography data to the SVM for training. The two models make predictions separately and then perform fusion. Additionally, the code attempts various fusion methods."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "def rf_svm_late_fusion(SVC_parameters: dict, ensemble_method: int, num_validation_indices: int = 2) -> None:\n",
    "    assert 0 <= ensemble_method < 8\n",
    "\n",
    "    # Calculate evaluation metrics for the given true and predicted labels\n",
    "    def cal_metrics(y_true: np.ndarray, y_pred: np.ndarray) -> list:\n",
    "        ac = accuracy_score(y_true, y_pred)\n",
    "        pr = precision_score(y_true, y_pred, average='macro', zero_division=0)\n",
    "        re = recall_score(y_true, y_pred, average='macro')\n",
    "        f1 = f1_score(y_true, y_pred, average='macro')\n",
    "        return [ac, pr, re, f1]\n",
    "\n",
    "    # Load training data\n",
    "    X, y = load_data(path=train_path, downsampling=True, concat=False)\n",
    "\n",
    "    rf_scores = []\n",
    "    svm_scores = []\n",
    "\n",
    "    # Calculate metrics if ensemble method is weighted averaging (1 to 4)\n",
    "    if 1 <= ensemble_method <= 4:\n",
    "        validation_indices = np.random.choice(range(len(X)), num_validation_indices, replace=False)\n",
    "        for i in validation_indices:\n",
    "            X_t = np.concatenate(X[:i] + X[i+1:], axis=0)\n",
    "            X_t_rf = np.take(X_t, range(0, 66), axis=2).reshape(X_t.shape[0], -1)\n",
    "            X_t_svm = np.take(X_t, range(66, 70), axis=2).reshape(X_t.shape[0], -1)\n",
    "            y_t = np.concatenate(y[:i] + y[i+1:])\n",
    "\n",
    "            X_v = X[i]\n",
    "            X_v_rf = np.take(X_v, range(0, 66), axis=2).reshape(X_v.shape[0], -1)\n",
    "            X_v_svm = np.take(X_v, range(66, 70), axis=2).reshape(X_v.shape[0], -1)\n",
    "            y_v = y[i]\n",
    "\n",
    "            rf = RandomForestClassifier(random_state=42)\n",
    "            rf.fit(X_t_rf, y_t)\n",
    "\n",
    "            svm = SVC(**SVC_parameters)\n",
    "            svm.fit(X_t_svm, y_t)\n",
    "\n",
    "            rf_pred = rf.predict(X_v_rf)\n",
    "            svm_pred = svm.predict(X_v_svm)\n",
    "\n",
    "            rf_scores.append(cal_metrics(y_v, rf_pred))\n",
    "            svm_scores.append(cal_metrics(y_v, svm_pred))\n",
    "\n",
    "        rf_scores = np.mean(rf_scores, axis=0)\n",
    "        svm_scores = np.mean(svm_scores, axis=0)\n",
    "\n",
    "        print(rf_scores, svm_scores)\n",
    "\n",
    "    X, y = np.concatenate(X, axis=0), np.concatenate(y, axis=0)\n",
    "    X_rf = np.take(X, range(0, 66), axis=2).reshape(X.shape[0], -1)\n",
    "    X_svm = np.take(X, range(66, 70), axis=2).reshape(X.shape[0], -1)\n",
    "\n",
    "    rf = RandomForestClassifier(random_state=42)\n",
    "    rf.fit(X_rf, y)\n",
    "\n",
    "    svm = SVC(**SVC_parameters)\n",
    "    svm.fit(X_svm, y)\n",
    "\n",
    "    X_v, y_v = load_data(path=validation_path, downsampling=False, concat=True, seg_parameters={'min_frame': 0})\n",
    "    X_v_rf = np.take(X_v, range(0, 66), axis=2).reshape(X_v.shape[0], -1)\n",
    "    X_v_svm = np.take(X_v, range(66, 70), axis=2).reshape(X_v.shape[0], -1)\n",
    "\n",
    "    rf_pred = rf.predict_proba(X_v_rf)\n",
    "    print(classification_report(y_v, np.argmax(rf_pred, axis=1)))\n",
    "    svm_pred = svm.predict_proba(X_v_svm)\n",
    "    print(classification_report(y_v, np.argmax(svm_pred, axis=1)))\n",
    "\n",
    "    final_pred = ensemble_predict(np.array([rf_pred, svm_pred]), np.array([rf_scores, svm_scores]), ensemble_method)\n",
    "\n",
    "    print(confusion_matrix(y_v, final_pred))\n",
    "    print(classification_report(y_v, final_pred))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.94      0.73      0.83      2706\n",
      "         1.0       0.06      0.28      0.10       166\n",
      "\n",
      "    accuracy                           0.71      2872\n",
      "   macro avg       0.50      0.51      0.46      2872\n",
      "weighted avg       0.89      0.71      0.78      2872\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.97      0.97      0.97      2706\n",
      "         1.0       0.48      0.48      0.48       166\n",
      "\n",
      "    accuracy                           0.94      2872\n",
      "   macro avg       0.72      0.72      0.72      2872\n",
      "weighted avg       0.94      0.94      0.94      2872\n",
      "\n",
      "2872 data are predicted using combined results of 2 modalities\n",
      "[[2600  106]\n",
      " [ 103   63]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.96      0.96      2706\n",
      "         1.0       0.37      0.38      0.38       166\n",
      "\n",
      "    accuracy                           0.93      2872\n",
      "   macro avg       0.67      0.67      0.67      2872\n",
      "weighted avg       0.93      0.93      0.93      2872\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rf_svm_late_fusion({'kernel': 'rbf', 'gamma': 'auto', 'probability': True, 'random_state': 42}, 5)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.89588407 0.79132017 0.73788667 0.75598024] [0.88534111 0.44267056 0.5        0.46817063]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.94      0.73      0.83      2706\n",
      "         1.0       0.06      0.28      0.10       166\n",
      "\n",
      "    accuracy                           0.71      2872\n",
      "   macro avg       0.50      0.51      0.46      2872\n",
      "weighted avg       0.89      0.71      0.78      2872\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.97      0.97      0.97      2706\n",
      "         1.0       0.48      0.48      0.48       166\n",
      "\n",
      "    accuracy                           0.94      2872\n",
      "   macro avg       0.72      0.72      0.72      2872\n",
      "weighted avg       0.94      0.94      0.94      2872\n",
      "\n",
      "2872 data are predicted using combined results of 2 modalities\n",
      "[[2600  106]\n",
      " [ 103   63]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.96      0.96      2706\n",
      "         1.0       0.37      0.38      0.38       166\n",
      "\n",
      "    accuracy                           0.93      2872\n",
      "   macro avg       0.67      0.67      0.67      2872\n",
      "weighted avg       0.93      0.93      0.93      2872\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rf_svm_late_fusion({'kernel': 'rbf', 'gamma': 'auto', 'probability': True, 'random_state': 42}, 1, 3)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.80829213 0.67149338 0.6391855  0.64771677] [0.83922226 0.41961113 0.5        0.45514884]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.94      0.73      0.83      2706\n",
      "         1.0       0.06      0.28      0.10       166\n",
      "\n",
      "    accuracy                           0.71      2872\n",
      "   macro avg       0.50      0.51      0.46      2872\n",
      "weighted avg       0.89      0.71      0.78      2872\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.97      0.97      0.97      2706\n",
      "         1.0       0.48      0.48      0.48       166\n",
      "\n",
      "    accuracy                           0.94      2872\n",
      "   macro avg       0.72      0.72      0.72      2872\n",
      "weighted avg       0.94      0.94      0.94      2872\n",
      "\n",
      "2872 data are predicted using combined results of 2 modalities\n",
      "[[2392  314]\n",
      " [ 109   57]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.88      0.92      2706\n",
      "         1.0       0.15      0.34      0.21       166\n",
      "\n",
      "    accuracy                           0.85      2872\n",
      "   macro avg       0.56      0.61      0.57      2872\n",
      "weighted avg       0.91      0.85      0.88      2872\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rf_svm_late_fusion({'kernel': 'rbf', 'gamma': 'auto', 'probability': True, 'random_state': 42}, 2, 3)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9521202  0.91784361 0.73905229 0.76893646] [0.92210324 0.46105162 0.5        0.47965816]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.94      0.73      0.83      2706\n",
      "         1.0       0.06      0.28      0.10       166\n",
      "\n",
      "    accuracy                           0.71      2872\n",
      "   macro avg       0.50      0.51      0.46      2872\n",
      "weighted avg       0.89      0.71      0.78      2872\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.97      0.97      0.97      2706\n",
      "         1.0       0.48      0.48      0.48       166\n",
      "\n",
      "    accuracy                           0.94      2872\n",
      "   macro avg       0.72      0.72      0.72      2872\n",
      "weighted avg       0.94      0.94      0.94      2872\n",
      "\n",
      "2872 data are predicted using combined results of 2 modalities\n",
      "[[2472  234]\n",
      " [ 107   59]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.91      0.94      2706\n",
      "         1.0       0.20      0.36      0.26       166\n",
      "\n",
      "    accuracy                           0.88      2872\n",
      "   macro avg       0.58      0.63      0.60      2872\n",
      "weighted avg       0.91      0.88      0.90      2872\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rf_svm_late_fusion({'kernel': 'rbf', 'gamma': 'auto', 'probability': True, 'random_state': 42}, 3, 3)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.77580811 0.72715685 0.58813526 0.59629894] [0.81865369 0.40932684 0.5        0.44519793]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.94      0.73      0.83      2706\n",
      "         1.0       0.06      0.28      0.10       166\n",
      "\n",
      "    accuracy                           0.71      2872\n",
      "   macro avg       0.50      0.51      0.46      2872\n",
      "weighted avg       0.89      0.71      0.78      2872\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.97      0.97      0.97      2706\n",
      "         1.0       0.48      0.48      0.48       166\n",
      "\n",
      "    accuracy                           0.94      2872\n",
      "   macro avg       0.72      0.72      0.72      2872\n",
      "weighted avg       0.94      0.94      0.94      2872\n",
      "\n",
      "2872 data are predicted using combined results of 2 modalities\n",
      "[[2517  189]\n",
      " [ 104   62]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.93      0.94      2706\n",
      "         1.0       0.25      0.37      0.30       166\n",
      "\n",
      "    accuracy                           0.90      2872\n",
      "   macro avg       0.60      0.65      0.62      2872\n",
      "weighted avg       0.92      0.90      0.91      2872\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rf_svm_late_fusion({'kernel': 'rbf', 'gamma': 'auto', 'probability': True, 'random_state': 42}, 4, 3)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Since the performance of the Random Forest was found to be poor, the following code replaces the Random Forest Classifier with the AdaBoostClassifier for experimentation."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "def ada_svm_late_fusion(SVC_parameters: dict, ensemble_method: int, num_validation_indices: int = 2) -> None:\n",
    "    assert 0 <= ensemble_method < 8\n",
    "\n",
    "    # Calculate evaluation metrics for the given true and predicted labels\n",
    "    def cal_metrics(y_true: np.ndarray, y_pred: np.ndarray) -> list:\n",
    "        ac = accuracy_score(y_true, y_pred)\n",
    "        pr = precision_score(y_true, y_pred, average='macro', zero_division=0)\n",
    "        re = recall_score(y_true, y_pred, average='macro')\n",
    "        f1 = f1_score(y_true, y_pred, average='macro')\n",
    "        return [ac, pr, re, f1]\n",
    "\n",
    "    # Load training data\n",
    "    X, y = load_data(path=train_path, downsampling=True, concat=False)\n",
    "\n",
    "    ada_scores = []\n",
    "    svm_scores = []\n",
    "\n",
    "    # Calculate metrics if ensemble method is weighted averaging (1 to 4)\n",
    "    if 1 <= ensemble_method <= 4:\n",
    "        validation_indices = np.random.choice(range(len(X)), num_validation_indices, replace=False)\n",
    "        for i in validation_indices:\n",
    "            X_t = np.concatenate(X[:i] + X[i+1:], axis=0)\n",
    "            X_t_ada = np.take(X_t, range(0, 66), axis=2).reshape(X_t.shape[0], -1)\n",
    "            X_t_svm = np.take(X_t, range(66, 70), axis=2).reshape(X_t.shape[0], -1)\n",
    "            y_t = np.concatenate(y[:i] + y[i+1:])\n",
    "\n",
    "            X_v = X[i]\n",
    "            X_v_ada = np.take(X_v, range(0, 66), axis=2).reshape(X_v.shape[0], -1)\n",
    "            X_v_svm = np.take(X_v, range(66, 70), axis=2).reshape(X_v.shape[0], -1)\n",
    "            y_v = y[i]\n",
    "\n",
    "            ada = AdaBoostClassifier(random_state=42)\n",
    "            ada.fit(X_t_ada, y_t)\n",
    "\n",
    "            svm = SVC(**SVC_parameters)\n",
    "            svm.fit(X_t_svm, y_t)\n",
    "\n",
    "            ada_pred = ada.predict(X_v_ada)\n",
    "            svm_pred = svm.predict(X_v_svm)\n",
    "\n",
    "            ada_scores.append(cal_metrics(y_v, ada_pred))\n",
    "            svm_scores.append(cal_metrics(y_v, svm_pred))\n",
    "\n",
    "        ada_scores = np.mean(ada_scores, axis=0)\n",
    "        svm_scores = np.mean(svm_scores, axis=0)\n",
    "\n",
    "        print(ada_scores, svm_scores)\n",
    "\n",
    "    X, y = np.concatenate(X, axis=0), np.concatenate(y, axis=0)\n",
    "    X_ada = np.take(X, range(0, 66), axis=2).reshape(X.shape[0], -1)\n",
    "    X_svm = np.take(X, range(66, 70), axis=2).reshape(X.shape[0], -1)\n",
    "\n",
    "    ada = AdaBoostClassifier(random_state=42)\n",
    "    ada.fit(X_ada, y)\n",
    "\n",
    "    svm = SVC(**SVC_parameters)\n",
    "    svm.fit(X_svm, y)\n",
    "\n",
    "    X_v, y_v = load_data(path=validation_path, downsampling=False, concat=True, seg_parameters={'min_frame': 0})\n",
    "    X_v_ada = np.take(X_v, range(0, 66), axis=2).reshape(X_v.shape[0], -1)\n",
    "    X_v_svm = np.take(X_v, range(66, 70), axis=2).reshape(X_v.shape[0], -1)\n",
    "\n",
    "    ada_pred = ada.predict_proba(X_v_ada)\n",
    "    print(classification_report(y_v, np.argmax(ada_pred, axis=1)))\n",
    "    svm_pred = svm.predict_proba(X_v_svm)\n",
    "    print(classification_report(y_v, np.argmax(svm_pred, axis=1)))\n",
    "\n",
    "    final_pred = ensemble_predict(np.array([ada_pred, svm_pred]), np.array([ada_scores, svm_scores]), ensemble_method)\n",
    "\n",
    "    print(confusion_matrix(y_v, final_pred))\n",
    "    print(classification_report(y_v, final_pred))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The following function calls might take a long time to run."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.94      0.95      0.95      2706\n",
      "         1.0       0.08      0.07      0.07       166\n",
      "\n",
      "    accuracy                           0.90      2872\n",
      "   macro avg       0.51      0.51      0.51      2872\n",
      "weighted avg       0.89      0.90      0.90      2872\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.97      0.97      0.97      2706\n",
      "         1.0       0.48      0.48      0.48       166\n",
      "\n",
      "    accuracy                           0.94      2872\n",
      "   macro avg       0.72      0.72      0.72      2872\n",
      "weighted avg       0.94      0.94      0.94      2872\n",
      "\n",
      "2872 data are predicted using combined results of 2 modalities\n",
      "[[2626   80]\n",
      " [  88   78]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.97      0.97      0.97      2706\n",
      "         1.0       0.49      0.47      0.48       166\n",
      "\n",
      "    accuracy                           0.94      2872\n",
      "   macro avg       0.73      0.72      0.73      2872\n",
      "weighted avg       0.94      0.94      0.94      2872\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ada_svm_late_fusion({'kernel': 'rbf', 'gamma': 'auto', 'probability': True, 'random_state': 42}, 5)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.82880308 0.69042592 0.72795438 0.65449831] [0.83472678 0.41736339 0.5        0.45375127]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.94      0.95      0.95      2706\n",
      "         1.0       0.08      0.07      0.07       166\n",
      "\n",
      "    accuracy                           0.90      2872\n",
      "   macro avg       0.51      0.51      0.51      2872\n",
      "weighted avg       0.89      0.90      0.90      2872\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.97      0.97      0.97      2706\n",
      "         1.0       0.48      0.48      0.48       166\n",
      "\n",
      "    accuracy                           0.94      2872\n",
      "   macro avg       0.72      0.72      0.72      2872\n",
      "weighted avg       0.94      0.94      0.94      2872\n",
      "\n",
      "2872 data are predicted using combined results of 2 modalities\n",
      "[[2629   77]\n",
      " [  88   78]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.97      0.97      0.97      2706\n",
      "         1.0       0.50      0.47      0.49       166\n",
      "\n",
      "    accuracy                           0.94      2872\n",
      "   macro avg       0.74      0.72      0.73      2872\n",
      "weighted avg       0.94      0.94      0.94      2872\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ada_svm_late_fusion({'kernel': 'rbf', 'gamma': 'auto', 'probability': True, 'random_state': 42}, 4, 3)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
