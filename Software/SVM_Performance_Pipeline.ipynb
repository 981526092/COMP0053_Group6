{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from typing import Union\n",
    "\n",
    "import numpy as np\n",
    "import scipy.io\n",
    "from scipy.stats import mode\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.svm import SVC, LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "train_path = \"CoordinateData\\\\train\"\n",
    "validation_path = \"CoordinateData\\\\validation\""
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "def segment_data(data: np.ndarray, window_size: int = 180, overlap_ratio: float = 0.75, by_type: bool = True, min_frame: int = 12) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Segment the input data into smaller windows based on the given parameters.\n",
    "\n",
    "    Args:\n",
    "        data (np.ndarray): Input data with shape (num_samples, num_features).\n",
    "        window_size (int, optional): The length of each window. Defaults to 180.\n",
    "        overlap_ratio (float, optional): The ratio of overlap between consecutive windows. Defaults to 0.75.\n",
    "        by_type (bool, optional): Whether to segment the data by type (assuming the 71st feature is the type). Defaults to True.\n",
    "        min_frame (int, optional): The minimum number of frames required to create a new instance. Defaults to 12.\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: The segmented data with shape (num_windows, window_size, num_features).\n",
    "    \"\"\"\n",
    "\n",
    "    # Check the input constraints\n",
    "    assert data.shape[0] > 0\n",
    "    assert window_size > 0\n",
    "    assert 0 <= overlap_ratio < 1\n",
    "    assert 0 <= min_frame < window_size\n",
    "\n",
    "    dim = data.shape[1]\n",
    "    instances = []\n",
    "\n",
    "    if not by_type:\n",
    "        instances.append(data)\n",
    "    else:\n",
    "        assert data.shape[1] >= 71\n",
    "\n",
    "        num_data = data.shape[0]\n",
    "        left, right = 0, 1\n",
    "        pre_type = -1\n",
    "        cur_type = data[left, 70]\n",
    "\n",
    "        # Segment the data by exercise type\n",
    "        while right < num_data:\n",
    "            if data[right, 70] == cur_type:\n",
    "                right += 1\n",
    "                continue\n",
    "\n",
    "            if right - left <= min_frame:\n",
    "                left = right\n",
    "                cur_type = data[left, 70]\n",
    "                right += 1\n",
    "                continue\n",
    "\n",
    "            new_instance = np.take(data, range(left, right), axis=0)\n",
    "            if pre_type == new_instance[0, 70]:\n",
    "                instances[-1] = np.vstack([instances[-1], new_instance])\n",
    "            else:\n",
    "                instances.append(new_instance)\n",
    "\n",
    "            left = right\n",
    "            pre_type = cur_type\n",
    "            cur_type = data[left, 70]\n",
    "            right += 1\n",
    "\n",
    "        # Handle the remaining data\n",
    "        new_instance = np.take(data, range(left, right), axis=0)\n",
    "        last = instances[-1]\n",
    "        if last[0, 70] == new_instance[0, 70]:\n",
    "            instances[-1] = np.vstack([last, new_instance])\n",
    "        else:\n",
    "            instances.append(new_instance)\n",
    "\n",
    "    # print(len(instances))\n",
    "\n",
    "    step_size = int(window_size * (1 - overlap_ratio))\n",
    "    windows = []\n",
    "\n",
    "    # Create windows for each instance\n",
    "    for instance in instances:\n",
    "        if instance.shape[0] < window_size:\n",
    "            instance = np.vstack([instance, np.zeros((window_size - instance.shape[0], dim))])\n",
    "            windows.append(instance)\n",
    "            continue\n",
    "\n",
    "        if (instance.shape[0] - window_size) % step_size != 0:\n",
    "            pad_size = step_size - (instance.shape[0] - window_size) % step_size\n",
    "            instance = np.vstack([instance, np.zeros((pad_size, dim))])\n",
    "\n",
    "        for i in range(0, instance.shape[0] - window_size + 1, step_size):\n",
    "            windows.append(np.take(instance, range(i, i + window_size), axis=0))\n",
    "\n",
    "    return np.array(windows)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "def load_data(path: str, downsampling: bool, concat: bool, seg_parameters: dict = None) -> (Union[list, np.ndarray], Union[list, np.ndarray]):\n",
    "    X_list = []\n",
    "    y_list = []\n",
    "\n",
    "    selected_data_list = []\n",
    "\n",
    "    # Iterate through the files in the provided path\n",
    "    for file in os.listdir(path):\n",
    "        mat = scipy.io.loadmat(os.path.join(path, file))\n",
    "\n",
    "        # If downsampling is True, ignore data with only one unique value in column 72\n",
    "        if downsampling and np.unique(mat['data'][:, 72]).size == 1:\n",
    "            continue\n",
    "        else:\n",
    "            selected_data_list.append(mat['data'])\n",
    "\n",
    "    # Process and segment the selected data files\n",
    "    for data in selected_data_list:\n",
    "\n",
    "        # If seg_parameters are provided, segment the data using those parameters\n",
    "        processed_data = segment_data(data, **seg_parameters) if seg_parameters else segment_data(data)\n",
    "\n",
    "        # Extract feature data (columns 0 to 69) and labels (column 72)\n",
    "        X_segmented = processed_data[:, :, 0:70]\n",
    "        y_segmented = processed_data[:, :, 72]\n",
    "        y_segmented = np.apply_along_axis(lambda x: mode(x)[0], 1, y_segmented)\n",
    "\n",
    "        X_list.append(X_segmented)\n",
    "        y_list.append(y_segmented.flatten())\n",
    "\n",
    "    # If concat is True, concatenate the lists into numpy arrays\n",
    "    if concat:\n",
    "        return np.concatenate(X_list, axis=0), np.concatenate(y_list, axis=0)\n",
    "\n",
    "    return X_list, y_list"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "This notebook aims to examine the performance of SVM on this dataset and analyze whether SVM is suitable for various modalities. Through experimentation, it was found that the coordinate information might have a low detection accuracy for positive cases due to its high dimensionality and scarce positive samples, even though the detection accuracy for negative cases is quite high. On the other hand, using sEMG data alone to train the SVM results in a reasonably accurate outcome (F1-score 0.72)."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "X, y = load_data(path=train_path, downsampling=True, concat=True)\n",
    "X_v, y_v = load_data(path=validation_path, downsampling=False, concat=True, seg_parameters={'min_frame': 0})"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "svm_parameters = {'kernel': 'rbf', 'gamma': 'auto', 'probability': True, 'random_state': 42}    # , 'class_weight': 'balanced'"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.94      1.00      0.97      2706\n",
      "         1.0       0.00      0.00      0.00       166\n",
      "\n",
      "    accuracy                           0.94      2872\n",
      "   macro avg       0.47      0.50      0.49      2872\n",
      "weighted avg       0.89      0.94      0.91      2872\n",
      "\n"
     ]
    }
   ],
   "source": [
    "svm_1 = SVC(**svm_parameters)\n",
    "\n",
    "X_svm = np.take(X, range(0, 66), axis=2).reshape(X.shape[0], -1)\n",
    "\n",
    "svm_1.fit(X_svm, y)\n",
    "\n",
    "X_v_svm = np.take(X_v, range(0, 66), axis=2).reshape(X_v.shape[0], -1)\n",
    "\n",
    "pred = svm_1.predict_proba(X_v_svm)\n",
    "print(classification_report(y_v, np.argmax(pred, axis=1), zero_division=0))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.97      0.97      0.97      2706\n",
      "         1.0       0.48      0.48      0.48       166\n",
      "\n",
      "    accuracy                           0.94      2872\n",
      "   macro avg       0.72      0.72      0.72      2872\n",
      "weighted avg       0.94      0.94      0.94      2872\n",
      "\n"
     ]
    }
   ],
   "source": [
    "svm_2 = SVC(**svm_parameters)\n",
    "\n",
    "X_svm = np.take(X, range(66, 70), axis=2).reshape(X.shape[0], -1)\n",
    "\n",
    "svm_2.fit(X_svm, y)\n",
    "\n",
    "X_v_svm = np.take(X_v, range(66, 70), axis=2).reshape(X_v.shape[0], -1)\n",
    "\n",
    "pred = svm_2.predict_proba(X_v_svm)\n",
    "print(classification_report(y_v, np.argmax(pred, axis=1), zero_division=0))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.94      1.00      0.97      2706\n",
      "         1.0       0.00      0.00      0.00       166\n",
      "\n",
      "    accuracy                           0.94      2872\n",
      "   macro avg       0.47      0.50      0.49      2872\n",
      "weighted avg       0.89      0.94      0.91      2872\n",
      "\n"
     ]
    }
   ],
   "source": [
    "svm_3 = SVC(**svm_parameters)\n",
    "\n",
    "X_svm = np.take(X, range(0, 70), axis=2).reshape(X.shape[0], -1)\n",
    "\n",
    "svm_3.fit(X_svm, y)\n",
    "\n",
    "X_v_svm = np.take(X_v, range(0, 70), axis=2).reshape(X_v.shape[0], -1)\n",
    "\n",
    "pred = svm_3.predict_proba(X_v_svm)\n",
    "print(classification_report(y_v, np.argmax(pred, axis=1), zero_division=0))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.90      0.93      2706\n",
      "         1.0       0.22      0.46      0.30       166\n",
      "\n",
      "    accuracy                           0.87      2872\n",
      "   macro avg       0.59      0.68      0.61      2872\n",
      "weighted avg       0.92      0.87      0.89      2872\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    }
   ],
   "source": [
    "svm_4 = LinearSVC(random_state=42)\n",
    "\n",
    "X_svm = np.take(X, range(66, 70), axis=2).reshape(X.shape[0], -1)\n",
    "\n",
    "svm_4.fit(X_svm, y)\n",
    "\n",
    "X_v_svm = np.take(X_v, range(66, 70), axis=2).reshape(X_v.shape[0], -1)\n",
    "\n",
    "pred = svm_4.predict(X_v_svm)\n",
    "print(classification_report(y_v, pred, zero_division=0))"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
